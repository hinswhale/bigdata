## 资源调优篇
### executors
1. executors
   - num-executors
   
   每个Spark作业的运行一般设置50~100个左右的Executor进程比较合适，设置太少或太多的Executor进程都不好。设置的太少，无法充分利用集群资源；设置的太多的话，大部分队列可能无法给予充分的资源。
   - executor-memory
   
     * 该参数用于设置每个Executor进程的内存
     * 每个Executor进程的内存设置4G~8G较为合适
     * num-executors乘以executor-memory，是不能超过队列的最大内存量的
     * 如果你是跟团队里其他人共享这个资源队列，那么申请的内存量最好不要超过资源队列最大总内存的1/3~1/2，避免你自己的Spark作业占用了队列所有的资源，导致别的同学的作业无法运行
   - executor-cores
     * 该参数用于设置每个Executor进程的CPU core数量。
     * Executor的CPU core数量设置为2~4个较为合适。
2. driver
      driver-memory
     - 参数说明：该参数用于设置Driver进程的内存。
     - 参数调优建议：Driver的内存通常来说不设置，或者设置1G左右应该就够了。唯一需要注意的一点是，如果需要使用collect算子将RDD的数据全部拉取到Driver上进行处理，那么必须确保Driver的内存足够大，否则会出现OOM内存溢出的问题。
3. 并行度
   1. spark.default.parallelism
   - 参数说明：该参数用于设置每个stage的默认task数量。
4. 网络超时
5. spark.storage.memoryFraction
6. spark.shuffle.memoryFraction

```shell
./bin/spark-submit \
  --master yarn-cluster \
  --num-executors 100 \
  --executor-memory 6G \
  --executor-cores 4 \
  --driver-memory 1G \
  --conf spark.default.parallelism=1000 \
  --conf spark.storage.memoryFraction=0.5 \
  --conf spark.shuffle.memoryFraction=0.3 \
```
