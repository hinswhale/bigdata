# ğŸ“– spark
- [sparkåŸºç¡€](#sparkåŸºç¡€)
    - [æ¶æ„è®¾è®¡](æ¶æ„.md#æ¶æ„è®¾è®¡)
    - [è¿è¡Œæ¨¡å¼](æ¶æ„.md#è¿è¡Œæ¨¡å¼)
        - [local](æ¶æ„.md#local)
        - [standalone](æ¶æ„.md#standalone)
        - [yarn](æ¶æ„.md#yarn)
    - [ç¯å¢ƒæ­å»º](æ¶æ„.md#ç¯å¢ƒæ­å»º)
    - [åŸºç¡€æ¦‚å¿µ](æ¶æ„.md#åŸºç¡€æ¦‚å¿µ)
    - [ä»»åŠ¡åŸºæœ¬æµç¨‹](æ¶æ„.md#ä»»åŠ¡åŸºæœ¬æµç¨‹)
    - [å‚è€ƒèµ„æ–™](æ¶æ„.md#å‚è€ƒèµ„æ–™)
- [RDDåŸºç¡€](#RDDåŸºç¡€)
    - [å¸¸ç”¨RDDç®—å­](RDD/README.md)
    - [ç´¯åŠ å™¨](#ç´¯åŠ å™¨)
        - [ç´¯åŠ å™¨æ³¨æ„é—®é¢˜](#ç´¯åŠ å™¨æ³¨æ„é—®é¢˜)
        - [è‡ªå®šä¹‰ç´¯åŠ å™¨](#è‡ªå®šä¹‰ç´¯åŠ å™¨)
    - [å¹¿æ’­å˜é‡](#å¹¿æ’­å˜é‡)
        - [å®ä¾‹](#å®ä¾‹)
  - [å¼€å‘è°ƒä¼˜ç¯‡](sparkå¼€å‘è°ƒä¼˜ç¯‡.md)
  - [èµ„æºè°ƒä¼˜ç¯‡](sparkèµ„æºè°ƒä¼˜ç¯‡.md)
    - [JVMçš„åŸºæœ¬æ¶æ„](https://www.cnblogs.com/qingyunzong/p/8973748.html)
    - [JVMçš„GCåƒåœ¾æ”¶é›†å™¨](https://www.cnblogs.com/qingyunzong/p/8973857.html)
  - [æ•°æ®å€¾æ–œè°ƒä¼˜](æ•°æ®å€¾æ–œè°ƒä¼˜.md#æ•°æ®å€¾æ–œè°ƒä¼˜)
    - [æŸä¸ªtaskæ‰§è¡Œç‰¹åˆ«æ…¢çš„æƒ…å†µ](æ•°æ®å€¾æ–œè°ƒä¼˜.md#æŸä¸ªtaskæ‰§è¡Œç‰¹åˆ«æ…¢çš„æƒ…å†µ)
    - [è§£å†³æ–¹æ¡ˆ](æ•°æ®å€¾æ–œè°ƒä¼˜.md#è§£å†³æ–¹æ¡ˆ)
  - [Shuffleè°ƒä¼˜](https://www.cnblogs.com/qingyunzong/p/8954552.html)
  - [Sparkå†…å­˜æ¨¡å‹](https://www.cnblogs.com/qingyunzong/p/8955141.html)
- [å‚è€ƒèµ„æ–™](#å‚è€ƒèµ„æ–™)

# RDDåŸºç¡€

## ç´¯åŠ å™¨

```longAccumulator``` åˆ†å¸ƒå¼å…±äº«åªå†™å˜é‡

- æ— ç´¯åŠ å™¨
![img_6.png](../pic/æ— ç´¯åŠ å™¨.png)
- åŠ ç´¯åŠ å™¨
![img_7.png](../pic/åŠ ç´¯åŠ å™¨.png)

### æ³¨æ„äº‹é¡¹
- ç´¯åŠ å™¨åœ¨Driverç«¯å®šä¹‰èµ‹åˆå§‹å€¼ï¼Œç´¯åŠ å™¨åªèƒ½åœ¨Driverç«¯è¯»å–æœ€åçš„å€¼ï¼Œåœ¨Excutorç«¯æ›´æ–°ã€‚
- ç´¯åŠ å™¨ä¸æ˜¯ä¸€ä¸ªè°ƒä¼˜çš„æ“ä½œï¼Œå› ä¸ºå¦‚æœä¸è¿™æ ·åšï¼Œç»“æœæ˜¯é”™çš„

### ç´¯åŠ å™¨æ³¨æ„é—®é¢˜

- æ³¨æ„âš ï¸
    - å°‘åŠ ï¼šè½¬æ¢ç®—å­ä¸­è°ƒç”¨ç´¯åŠ å™¨ï¼Œå¦‚æœæ²¡æœ‰è°ƒç”¨è¡ŒåŠ¨ç®—å­çš„è¯ï¼Œé‚£ä¹ˆä¼šå‡ºç°å°‘åŠ çš„æƒ…å†µ
    - å¤šåŠ ï¼šè½¬æ¢ç®—å­ä¸­è°ƒç”¨ç´¯åŠ å™¨ï¼Œå¦‚æœå¤šæ¬¡è°ƒç”¨è¡ŒåŠ¨ç®—å­ï¼Œé‚£ä¹ˆä¼šå‡ºç°å¤šåŠ çš„æƒ…å†µ
    - ä¸€èˆ¬æƒ…å†µä¸‹ï¼Œç´¯åŠ å™¨ä¼šæ”¾åœ¨`è¡ŒåŠ¨ç®—å­`ä¸­è¿›è¡Œæ“ä½œ
- å®ä¾‹
    - æœªç”¨ç´¯åŠ å™¨ç‰ˆæœ¬
      ```scala
      val rdd = sc.makeRDD(List(1, 2, 3, 4))
    
          //reduce:åˆ†åŒºå†…è®¡ç®—ï¼Œåˆ†åŒºé—´è®¡ç®—
      //    val res: Int = rdd.reduce(_ + _)
      //    println(res)
    
          var sum = 0
          rdd.foreach(
            num=> sum = sum + num
          )
          println(sum)
      // sum=0 å› ä¸ºåˆ†åŒºï¼Œæ¯ä¸ªåˆ†åŒºsumåˆå§‹å€¼ä¸º0
      ```

    - ç´¯åŠ å™¨é‡å†™ç‰ˆæœ¬
      ```scala
      import org.apache.spark.util.LongAccumulator
      import org.apache.spark.{SparkConf, SparkContext}

      object Spark02_Acc {
        def main(args: Array[String]): Unit = {
    
          val sparkConf: SparkConf = new SparkConf().setMaster("local").setAppName("Acc")
          val sc = new SparkContext(sparkConf)
    
          val rdd = sc.makeRDD(List(1, 2, 3, 4))
          //è·å–ç³»ç»Ÿç´¯åŠ å™¨
          //Sparké»˜è®¤å°±æä¾›äº†ç®€å•æ•°æ®èšåˆçš„ç´¯åŠ å™¨
          val sumAcc: LongAccumulator = sc.longAccumulator("sum")
    
          //sc.doubleAccumulator()
          //sc.collectionAccumulator()
    
          rdd.foreach(
            num => {
              //ä½¿ç”¨ç´¯åŠ å™¨
              sumAcc.add(num)
            }
          )
    
          println(sumAcc.value)
    
          sc.stop()
        }
      }
      ```
    - å°‘åŠ æˆ–å¤šåŠ 
      ```scala
      val rdd = sc.makeRDD(List(1, 2, 3, 4))
      val sumAcc: LongAccumulator = sc.longAccumulator("sum")

      val mapRDD = rdd.map(
        num => {
          //ä½¿ç”¨ç´¯åŠ å™¨
          sumAcc.add(num)
        }
      )

      //è·å–ç´¯åŠ å™¨çš„å€¼
      //å°‘åŠ ï¼šè½¬æ¢ç®—å­ä¸­è°ƒç”¨ç´¯åŠ å™¨ï¼Œå¦‚æœæ²¡æœ‰è°ƒç”¨è¡ŒåŠ¨ç®—å­çš„è¯ï¼Œé‚£ä¹ˆä¼šå‡ºç°å°‘åŠ çš„æƒ…å†µ
      //å¤šåŠ ï¼šè½¬æ¢ç®—å­ä¸­è°ƒç”¨ç´¯åŠ å™¨ï¼Œå¦‚æœå¤šæ¬¡è°ƒç”¨è¡ŒåŠ¨ç®—å­ï¼Œé‚£ä¹ˆä¼šå‡ºç°å¤šåŠ çš„æƒ…å†µ
      //ä¸€èˆ¬æƒ…å†µä¸‹ï¼Œç´¯åŠ å™¨ä¼šæ”¾åœ¨è¡ŒåŠ¨ç®—å­ä¸­è¿›è¡Œæ“ä½œ
      mapRDD.collect()
      mapRDD.collect()
      println(sumAcc.value)
      ```

### è‡ªå®šä¹‰ç´¯åŠ å™¨

- å®ä¾‹ wordCount

   ```scala
    import org.apache.spark.util.{AccumulatorV2, LongAccumulator}
    import org.apache.spark.{SparkConf, SparkContext}
    
    import scala.collection.mutable
    
    object Spark04_Acc_WordCount {
      def main(args: Array[String]): Unit = {
    
        val sparkConf: SparkConf = new SparkConf().setMaster("local").setAppName("Acc")
        val sc = new SparkContext(sparkConf)
    
        val rdd = sc.makeRDD(List("hello", "world", "hello"))
        //ç´¯åŠ å™¨ï¼šWordCount
        //åˆ›å»ºç´¯åŠ å™¨å¯¹è±¡
        val wcAcc = new MyAccumulator()
        //å‘sparkè¿›è¡Œæ³¨å†Œ
        sc.register(wcAcc, "WordCountAcc")
    
        rdd.foreach(
          word => {
            //æ•°æ®çš„ç´¯åŠ ï¼ˆä½¿ç”¨ç´¯åŠ å™¨ï¼‰
            wcAcc.add(word)
          }
        )
    
        //è·å–ç´¯åŠ å™¨çš„ç»“æœ
        println(wcAcc.value)
        sc.stop()
      }
    
      /*
        è‡ªå®šä¹‰æ•°æ®ç´¯åŠ å™¨ï¼šWordCount
          1.ç»§æ‰¿è‡ªAccumulatorV2ï¼Œå®šä¹‰æ³›å‹
            INï¼šç´¯åŠ å™¨è¾“å…¥çš„æ•°æ®ç±»å‹ï¼šString
            OUTï¼šç´¯åŠ å™¨è¾“å‡ºçš„æ•°æ®ç±»å‹ï¼šmutable.Map[String, Long]
          2.é‡å†™æ–¹æ³•(6ä¸ª)
       */
      class MyAccumulator extends AccumulatorV2[String, mutable.Map[String, Long]] {
    
        private var wcMap = mutable.Map[String, Long]()
    
        //åˆ¤æ–­æ˜¯å¦ä¸ºåˆå§‹çŠ¶æ€
        override def isZero: Boolean = {
          wcMap.isEmpty
        }
    
        override def copy(): AccumulatorV2[String, mutable.Map[String, Long]] = {
          new MyAccumulator()
        }
    
        //é‡ç½®ç´¯åŠ å™¨
        override def reset(): Unit = {
          wcMap.clear()
        }
    
        //è·å–ç´¯åŠ å™¨éœ€è¦è®¡ç®—çš„å€¼
        override def add(word: String): Unit = {
          val newCnt = wcMap.getOrElse(word, 0L) + 1
          wcMap.update(word, newCnt)
        }
    
        //Driveråˆå¹¶å¤šä¸ªç´¯åŠ å™¨
        override def merge(other: AccumulatorV2[String, mutable.Map[String, Long]]): Unit = {
          val map1 = this.wcMap
          val map2 = other.value
    
          map2.foreach {
            case (word, count) => {
              val newCount = map1.getOrElse(word, 0L) + count
              map1.update(word, newCount)
            }
          }
        }
    
        //ç´¯åŠ å™¨ç»“æœ
        override def value: mutable.Map[String, Long] = {
          wcMap
        }
      }
    
    }
  
   ```

## å¹¿æ’­å˜é‡
` åˆ†å¸ƒå¼å…±äº«åªè¯»å˜é‡ `

- ä¸ä½¿ç”¨å¹¿æ’­å˜é‡
![img_6.png](../pic/ä¸ä½¿ç”¨å¹¿æ’­å˜é‡.png)
- ä½¿ç”¨å¹¿æ’­å˜é‡çš„æƒ…å†µ
![img_7.png](../pic/ä½¿ç”¨å¹¿æ’­å˜é‡.png)


### æ³¨æ„äº‹é¡¹
- èƒ½ä¸èƒ½å°†ä¸€ä¸ªRDDä½¿ç”¨å¹¿æ’­å˜é‡å¹¿æ’­å‡ºå»ï¼Ÿ

  ä¸èƒ½ï¼Œå› ä¸ºRDDæ˜¯ä¸å­˜å‚¨æ•°æ®çš„ã€‚å¯ä»¥å°†RDDçš„ç»“æœå¹¿æ’­å‡ºå»ã€‚
- å¹¿æ’­å˜é‡åªèƒ½åœ¨Driverç«¯å®šä¹‰ï¼Œä¸èƒ½åœ¨Executorç«¯å®šä¹‰ã€‚
- åœ¨Driverç«¯å¯ä»¥ä¿®æ”¹å¹¿æ’­å˜é‡çš„å€¼ï¼Œåœ¨Executorç«¯æ— æ³•ä¿®æ”¹å¹¿æ’­å˜é‡çš„å€¼ã€‚
- å¦‚æœexecutorç«¯ç”¨åˆ°äº†Driverçš„å˜é‡ï¼Œå¦‚æœä¸ä½¿ç”¨å¹¿æ’­å˜é‡åœ¨Executoræœ‰å¤šå°‘taskå°±æœ‰å¤šå°‘Driverç«¯çš„å˜é‡å‰¯æœ¬ã€‚
- å¦‚æœExecutorç«¯ç”¨åˆ°äº†Driverçš„å˜é‡ï¼Œå¦‚æœä½¿ç”¨å¹¿æ’­å˜é‡åœ¨æ¯ä¸ªExecutorä¸­åªæœ‰ä¸€ä»½Driverç«¯çš„å˜é‡å‰¯æœ¬ã€‚

### å®ä¾‹

- æœªåŠ å¹¿æ’­å˜é‡
    ```scala
    val rdd1 = sc.makeRDD(List(
     ("a", 1),
     ("b", 2),
     ("c", 3)
   ))

   val rdd2 = sc.makeRDD(List(
     ("a", 4),
     ("b", 5),
     ("c", 6)
   ))

   //joinä¼šå¯¼è‡´æ•°æ®é‡å‡ ä½•å¢é•¿ï¼Œå¹¶ä¸”ä¼šå½±å“shuffleçš„æ€§èƒ½ï¼Œä¸æ¨èä½¿ç”¨
   val joinRDD: RDD[(String, (Int, Int))] = rdd1.join(rdd2)
   joinRDD.collect().foreach(println)
   /*
     (a,(1,4))
     (b,(2,5))
     (c,(3,6))
   */
   ```

- æ— joinç‰ˆæœ¬[æ•°æ®é‡å¤§æ—¶ï¼Œæ€§èƒ½ä¸å¥½]

![img.png](../pic/core/å¹¿æ’­å˜é‡.png)

   ```scala
   val rdd1 = sc.makeRDD(List(
     ("a", 1),
     ("b", 2),
     ("c", 3)
   ))
    
   val map: mutable.Map[String, Int] = mutable.Map(("a", 4), ("b", 5), ("c", 6))
   rdd1.map {
     case (w, c) => {
       val i: Int = map.getOrElse(w, 0)
       (w, (c, i))
     }
   }.collect().foreach(println)
   ```

- å¹¿æ’­å˜é‡

![img.png](../pic/core/å¹¿æ’­å˜é‡1.png)

   ```scala
    val rdd1 = sc.makeRDD(List(
      ("a", 1),
      ("b", 2),
      ("c", 3)
    ))


    val map: mutable.Map[String, Int] = mutable.Map(("a", 4), ("b", 5), ("c", 6))

    //å°è£…å¹¿æ’­å˜é‡
    val bc: Broadcast[mutable.Map[String, Int]] = sc.broadcast(map)

    rdd1.map {
      case (w, c) => {
        //è®¿é—®å¹¿æ’­å˜é‡
        val i: Int = bc.value.getOrElse(w, 0)
        (w, (c, i))
      }
    }.collect().foreach(println)
  ```


# å‚è€ƒèµ„æ–™
- [Sparkæ€§èƒ½ä¼˜åŒ–æŒ‡å—â€”â€”é«˜çº§ç¯‡](https://tech.meituan.com/2016/05/12/spark-tuning-pro.html) ğŸ“š
- [Sparkæ€§èƒ½ä¼˜åŒ–æŒ‡å—â€”â€”åŸºç¡€ç¯‡](https://tech.meituan.com/2016/04/29/spark-tuning-basic.html) ğŸ“š
- [Sparkå­¦ä¹ ä¹‹è·¯ ï¼ˆå…«ï¼‰SparkCoreçš„è°ƒä¼˜ä¹‹å¼€å‘è°ƒä¼˜](https://www.cnblogs.com/qingyunzong/p/8946637.html#_label10)
- [Sparkæ€§èƒ½è°ƒä¼˜å®æˆ˜](https://time.geekbang.org/column/intro/100073401)
- [Sparkæ€§èƒ½è°ƒä¼˜å®æˆ˜_xiewenbo](https://www.cxyzjd.com/article/xiewenbo/50041613)
- https://changbo.tech/blog/19c2ab93.html